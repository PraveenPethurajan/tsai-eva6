## Questions:
1. What are Channels and Kernels (according to EVA)?
2. Why should we (nearly) always use 3x3 kernels?
3. How many times do we need to perform 3x3 convolutions operations to reach close to 1x1 from 199x199 (type each layer output like 199x199 > 197x197...)
4. How are kernels initialized?
5. What happens during the training of a DNN?

## Answers:
1. - Kernels : 
	  - Suppose you have an image and you want to extract some useful features out of it, that is when you will need kernels.
	  - Kernel is a feature extractor.
	  - It is a tool or matrix ( generally 3*3) that convolves over an image(matrix) or feature map to extract one feature.
	  - It extracts some information from the given image and the information is stored in Neuron.
	  - Kernel creates channels from an image (Collection of neurons is a channel).
	    - Eg: A vertical edge detector kernel will extract all vertical edges from an image and the collection of all vertical edges in that image is a channel.
	  - Each kernel makes its own channel.
   - Channels : 
	  - A channel is a collection of single type feature extracted by kernels.
	  - One channel is like a container, containing similar kind of information.
	  - Channels can be seen, but kernels cannot be seen.
	  - Information in channels depends on type of kernel/kernel values used to extract that information.
	  - At first level, one channel contains a single feature. 
	  	- Through subsequent layer, one channel can contain a combined low level information or features extracted from the previous layers as well. 
	  	- So after a few layers of convolution network, if we combine features from previous layers and see them as a single feature, that can be further contained with one channel to learn that particular feature.
	  	
2. - Smaller kernels results in less number of parameters.
	- Eg: Let us consider 5x5 image and if we want to extract a feature which covers all the pixels of image or say whose receptive field is entire image.
		- Then we can either use 5x5 kernel which is 5x5 = 25 parameters or we could use 2 layers of 3x3 kernels.
		- 1st kernel extracts 3x3 channel from the image and 2nd kernel extracts single feature from that channel, thus receptive field becomes whole image. 
		- But in this case, we have 2 layers of 3x3 kernels which is 2*3*3 = 18 parameters.
   	- As the image size increases, the difference between the number of parameters also increases drastically.

   - Smaller kernels = More features.
	- Assume we have a 7x7 image and we are trying to extract features out of it.
	- If we use 7x7 kernel, then we get only 1 feature out of the image.
	- If we use 5x5 kernel, then we get 3x3 channel of some feature depending on kernel values, thus 9 features in total.
	- If we use 3x3 kernel, then we get 5x5 channel and thus 25 features.
	- The more features we have, the better model training will be and also our predictions will be better.

   - Now a question arises, if smaller kernels are the best option, then why not a 2x2 or 1x1 kernel?
	- We should always use odd numbered kernels, reason will be revealed soon in upcoming sessions.
	- In case of 1x1 kernels, all you will be doing is just copy paste the pixel, without extracting any information from it.
