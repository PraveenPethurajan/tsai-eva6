# Assignment 3 - NUMBER AND SUM PREDICTOR

It takes two inputs.
- Image
- Random Number

Finally, predicts the sum of number present in Image and Random Number.

# Table of contents

- [Project Title](#project-title)
- [Table of contents](#table-of-contents)
- [Explanation - Work Flow](#installation)
- [Data Representation](#usage)
- [Data Generation Strategy](#development)
- [How 2 Inputs are Combined?](#contribute)
- [Results and Evaluation]
- [Which Loss Functions and Why?]
- [Footer]

# Explanation - Work Flow

- Create 2 Models
    - One for predicting the number present in Image Input
    - Second to perfrom and predict the addition
- ### Model 1 - MNIST Model
  - Use convolutional layers, relu activation function and max-pooling to build the model
  - Optimizer - Stochastic Gradient Descent (SGD randomly picks one data point from the whole data set to compute derivatives at each iteration to reduce the computations)
  - Loss Function - Negative log likelihood (It is used to minimize loss such that greater the confidence of correct class, lower the loss and lower the confidence of correct class, greater the loss)

![alt text](https://cdn.mathpix.com/snip/images/CpoT9c4tcXZYd_xIaByGDUSpFpK-RfyC8F24g6LH7rA.original.fullsize.png)

- ### Model 2 - Sum Model
  - Use fully connected layers only with 3 layers
  - Optimizer - Adam (For sparse gradients on noisy problems, since addition of 2 numbers is noisy because the 2 numbers can be any number)
  - Loss Function - Mean Squared Error (It is the best choice for Regression like problem)
![alt text](https://cdn.mathpix.com/snip/images/SFlkTFbriAthdkFeAxfMhZ-Xh1hdmV77E4cdFTRGWpI.original.fullsize.png)

- Train MNIST Model on MNIST Dataset
- Test Accuracy is around 98-99% for 1 to 5 epochs.
- Then generate the dataset for training Sum Model
- Load the dataset using Dataset class and train the sum model
- Both the models are trained individually.
- Finally, when an Image and Random Number is given,
  - Pass the image through MNIST model and predict the number
  - Pass the predicted number and random number in Sum model and predict the addition of those 2 numbers.
- So, the output of MNIST model along with random number is fed as input to Sum model

# Data Representation
- Input Image
    - Grayscale Image - So number of input channel = 1
    - Image Size = 28x28
    - Each image was represented as tensor of shape (number_of_images, number_of_channels, number_of_rows, number_of_columns) i.e., (1,1,28,28)
    - When the above Image was fed to model, it gave tensor of shape (1,1,1,10) as output,
        - where 10 is for number of classes (0-9)
    - Finally, the index of largest value(a scalar) was extracted and that is the prediction given by model for number present in image.
- Input Random Number
    - In Training,
        - Random pairs and their sum were generated.
        - Input for Sum Model was tensor of shape (1,2)
        - Input was converted to FloatTensor
        - Output for Sum Model was a scalar.
    - In Testing,
        - Output of MNIST Model and Random Number were combined as single tensor of shape (1,2)
        - Output of Sum Model was again a scalar.
        
# Data Generation Strategy

- MNIST Image Dataset
    - It is already available and is downloaded and used using Pytorch library.

- Random Numbers and its Sum
    - A function was written, which will generate 2 random numbers as input and add those 2 for output, thus creating a training instance.
 
- Finally, when model was evaluated, only a image from dataset and random number was given, the other number required was generated by MNIST model which predicts number present in input image.

# How 2 Inputs are Combined?

![alt text](https://cdn.mathpix.com/snip/images/SUdBj-06ggijw-qnTNvWSz3y0ZWzflR582n_xqvDGZI.original.fullsize.png)

# Results and Evaluation

- The results of MNIST model which predicts number present in Image were evaluated and its accuracy was 98-99% in 1 to 5 epochs.
- Accuracy kept increasing with each epoch.
- The results of Sum model was evaluated using RMSE(Root Mean Square Error) and its accuracy was not more than 25%.
- The overall results had accuracy of 20%

# Which Loss Functions and Why?
- MNIST Model
    - ### Negative log likelihood
        - It is used to minimize loss such that greater the confidence of correct class, lower the loss and lower the confidence of correct class, greater the loss
        - Since, the task of MNIST Model is classification between 10 classes, we want our model to predict the correct class with high accuracy.
        - So, we chose NLL Loss Function to train model such that it learns to predict with high confidence.
- Sum Model
    - ### Mean Squared Error
        - 

# Footer
[(Back to top)](#table-of-contents)

<!-- Let's also add a footer because I love footers and also you **can** use this to convey important info.

Let's make it an image because by now you have realised that multimedia in images == cool(*please notice the subtle programming joke). -->

Leave a star in GitHub, give a clap in Medium and share this guide if you found this helpful.

<!-- Add the footer here -->

<!-- ![Footer](https://github.com/navendu-pottekkat/awesome-readme/blob/master/fooooooter.png) -->
